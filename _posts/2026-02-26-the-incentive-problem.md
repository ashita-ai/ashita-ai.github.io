---
layout: post
title: "The Incentive Problem"
date: 2026-02-26
---

In 2015, IBM's Watson team cautioned leadership that the system was designed to identify word patterns and predict answers to trivia questions. It was not, as David Ferrucci put it, "an all-purpose answer box ready to take on the commercial world." The warning [fell on deaf ears](https://www.advisory.com/daily-briefing/2021/07/21/ibm-watson). "It wasn't the marketing message," Ferrucci said. He left IBM the following year.

IBM spent four billion dollars acquiring Watson Health companies. The [pattern of failures](https://spectrum.ieee.org/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care) in healthcare applications was not a technology problem. At Manipal Comprehensive Cancer Center, Watson achieved only 73% concordance on breast cancer treatment recommendations. At MD Anderson, the project was shelved after $62 million and four years. The models worked in the lab. What failed was the organizational structure that rewarded announcing AI initiatives over delivering them.

This is the incentive problem. AI projects fail not because the technology does not work, but because the people and organizations deploying them are optimized for different outcomes.

## The pilot incentive

PwC's George Korizis [put it bluntly](https://trullion.com/blog/why-95-of-ai-projects-fail-and-why-the-5-that-survive-matter/): "Eight out of ten clients that I see get stuck in pilot mode. They usually have no issue creating small, isolated wins. But most of them can't stitch those wins together to make a bigger impact."

The pattern is consistent. A pilot gets funded. A team builds a demo. The demo impresses executives. The pilot leader gets promoted or moves to a new company. The pilot sits in purgatory. S&P Global [found](https://www.spglobal.com/market-intelligence/en/news-insights/research/ai-experiences-rapid-adoption-but-with-mixed-outcomes-highlights-from-vote-ai-machine-learning) that 42% of companies abandoned most AI initiatives in 2025, up from 17% in 2024. On average, 46% of pilots are scrapped before they ever reach production.

The incentive structure is working exactly as designed. It is just not designed for production.

Pilot teams are rewarded for novelty and speed. A fast prototype that generates excitement is a career win. Whether that prototype survives the handoff to operations is someone else's problem. [Research on misaligned incentives](https://agility-at-scale.com/implementing/scaling-ai-projects/) in AI projects confirms: "If the pilot team is rewarded for fast prototype delivery, not long-term adoption, they may neglect production considerations."

The career timeline reinforces this. AI product managers [advance faster](https://www.gankinterview.com/en/blog/the-ultimate-2025-product-manager-career-planning-guide) than traditional PMs—what used to take five years now happens in eighteen months. The fastest path up is launching initiatives, not maintaining them. This is why [healthy metrics can coexist with broken agents](/blog/healthy-metrics-broken-agent/)—the people measuring are optimizing for different outcomes than the people using.

## The budget incentive

[60% of enterprise AI investment](https://menlovc.com/2024-the-state-of-generative-ai-in-the-enterprise/) comes from innovation budgets—temporary funds earmarked for new projects. Only 40% comes from permanent operational budgets. Innovation budgets are designed to launch things. They are not designed to keep things running. The result is [architectural decisions made during cheap pilots that create exponential cost multipliers at scale](/blog/the-token-tax/).

The structural bias toward CapEx over OpEx [compounds the problem](https://www.comarch.com/trade-and-services/ict/news/8-proven-it-cost-reduction-strategies-that-shift-spending-from-capex-to-opex/): "Without a clear plan for IT cost reduction, rising operational costs for legacy systems can consume your entire budget, leaving no room for the strategic projects that drive business growth."

This creates a perverse dynamic. The budget exists to start AI projects. Once they ship, they compete for maintenance dollars against everything else. The team that launched the pilot has moved on. The team inheriting it has no incentive to keep it alive—doing so drains resources from their own projects.

Big Tech is [pouring hundreds of billions](https://introl.com/blog/ai-infrastructure-financing-capex-opex-gpu-investment-guide-2025) into AI infrastructure: Amazon at $100–125B, Microsoft at $80B, Alphabet at $75–85B. Yet 80–95% of AI projects fail to deliver expected value. The money is there. The incentive to see projects through is not.

## The vendor incentive

The vendors selling AI tools have their own misalignment.

Seat-based pricing—the dominant SaaS model—[creates a trap](https://www.starthawk.io/blog/post/the-death-of-the-seat-based-license-pricing-for-outcomes-in-an-automated-world): "If you make your product better (more automated), you get paid less." A CRM with AI that automates what twenty salespeople did now requires only two. If you charge per seat, your revenue drops 90% even though your product is ten times more powerful.

Sierra's pricing analysis [makes the conflict explicit](https://sierra.ai/blog/outcome-based-pricing-for-ai-agents): "Legacy customer experience providers face a dilemma. Their revenue models depend on seat-based pricing. While these vendors may promote AI agents that autonomously resolve cases, they're trapped in a conflict: the more effective their AI becomes, the fewer contact center seats their clients need—undermining the provider's own revenue model."

The market is responding. Seat-based pricing [dropped from 21% to 15%](https://www.agilegrowthlabs.com/blog/seat-based-pricing-is-dead-how-ai-first-saas-companies-are-monetizing-with-outcome-based-pricing/) of companies in just twelve months. Companies that stick with per-seat pricing for AI products see 40% lower gross margins and 2.3x higher churn than those using usage or outcome-based models. The incentive structure is changing, but most enterprise contracts have not caught up.

## The handoff incentive

Harvard Business Review [documented five models](https://hbr.org/2018/08/how-to-hand-off-an-innovation-project-from-one-team-to-another) for handing off innovation projects to execution teams. The most common—the "Owner's Manual," where the innovation team documents their work and hands it over—is also the least effective. The execution team usually never reads the documentation.

"You can have the right portfolio of investments, the right metrics and governance, the right stage-gate development process, and the right talent on the right teams," the authors write, "but if you don't design the right handoffs between your teams, all of that planning falls apart."

The only model that reliably works is the "Hive": multidisciplinary teams that tackle challenges across the entire lifecycle, essentially eliminating the handoff. But most organizations are not structured this way. Innovation teams are measured on novelty. Execution teams are measured on reliability. When an innovation team succeeds and hands off to execution, the execution team [has zero incentive to adopt it](https://pmc.ncbi.nlm.nih.gov/articles/PMC8483614/). It disrupts their metrics. The innovation dies in the handoff, not in the lab.

## What works

The [companies that scale AI](/blog/when-ai-actually-works/) share a pattern: they restructure incentives so that launching and maintaining are the same team's job.

This means eliminating the handoff. If the team that builds the pilot also owns production, the pilot incentive disappears. If the budget comes from operational funds rather than innovation funds, the budget incentive disappears. If vendor contracts are tied to outcomes rather than seats, the vendor incentive aligns with yours.

McKinsey [found](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai) that high performers are three times more likely to fundamentally redesign workflows rather than just adding AI to existing processes. They establish employee incentives that reinforce adoption. They empower line managers rather than keeping decisions centralized in corporate AI labs. The common thread is pushing ownership down to the people who do the work and measuring what matters to the business, not what looks good in a demo.

## What I am still figuring out

The career incentive data is weaker than I expected. Plenty of anecdotal evidence that pilot launchers advance faster than production deliverers, but no rigorous longitudinal studies tracking promotion rates. The pattern is visible in behavior—people leave before production—but the causal mechanism is assumed rather than proven.

The organizational structure problem may be deeper than incentives alone. O'Reilly and Tushman's research on [organizational ambidexterity](https://journals.aom.org/doi/10.5465/amp.2013.0025) suggests that exploration and exploitation require fundamentally different capabilities: flexibility versus control, autonomy versus efficiency. Aligning incentives may not be enough if the organizational structure makes it impossible for the same team to do both.

---

IBM's Watson failure was not a failure of artificial intelligence. It was a failure of organizational incentives. The marketing message won. The technical caution lost. The $4 billion evaporated.

[The AI pilots that reach production](/blog/the-ai-pilot-graveyard/) are not the ones with better technology. They are the ones where the incentives aligned: where launching and maintaining were the same team's job, where success was measured in business outcomes rather than demos, where the budget survived past the announcement.

The technology usually works. The problem is everything else.
